{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "h94vXmlekqT8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LySoEmyPyOCD",
        "outputId": "c227e3d1-f05d-4f20-e7ab-724b99f6a8f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PyPDF2 import PdfReader\n",
        "\n",
        "pdf_file = open('/content/Harry Potter and the Prisoner of Azkaban.pdf', 'rb')\n",
        "\n",
        "pdf_reader = PdfReader(pdf_file)\n",
        "\n",
        "text = ''\n",
        "for page_num in range(len(pdf_reader.pages)):\n",
        "    page = pdf_reader.pages[page_num]\n",
        "    text += page.extract_text()\n",
        "pdf_file.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTiYU7d1ru4O",
        "outputId": "7b911fd4-c4bd-4ae1-ac66-875cefc9078e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:PyPDF2._reader:incorrect startxref pointer(3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FxmbzWlfvp93"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "text = re.sub(r'\\s+', ' ', text)\n",
        "text = text.replace('\\n', ' ')"
      ],
      "metadata": {
        "id": "NuQcWQguvudq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(text)"
      ],
      "metadata": {
        "id": "LHk_Ec8CztuS"
      },
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-pjx8WX0uHX",
        "outputId": "d36a59e7-1647-473f-9adb-105505a9d96e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "145934"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def add_newline(text, n=30):\n",
        "    words = text.split()\n",
        "    result = \"\"\n",
        "    count = 0\n",
        "    for word in words:\n",
        "        result += word + \" \"\n",
        "        count += 1\n",
        "        if count == n:\n",
        "            result += \"\\n\"\n",
        "            count = 0\n",
        "    return result.strip()\n",
        "\n",
        "\n",
        "formatted_text = add_newline(text, 20)\n",
        "# print(formatted_text)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "MO5SRiod6HyJ"
      },
      "execution_count": 195,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "def extract_dialogues_nlp(script_text):\n",
        "    doc = nlp(script_text)\n",
        "    dialogues = []\n",
        "    current_dialogue = []\n",
        "\n",
        "    for sent in doc.sents:\n",
        "        if sent.text.startswith(('INT.', 'EXT.')):\n",
        "            continue  # Skip scene headers\n",
        "        if sent.text.startswith(('HARRY', 'RON', 'HERMIONE')):\n",
        "            if current_dialogue:\n",
        "                dialogues.append(' '.join(current_dialogue))\n",
        "                current_dialogue = []\n",
        "            current_dialogue.append(sent.text)\n",
        "        elif current_dialogue:\n",
        "            current_dialogue.append(sent.text)\n",
        "\n",
        "    if current_dialogue:\n",
        "        dialogues.append(' '.join(current_dialogue))\n",
        "\n",
        "    return dialogues"
      ],
      "metadata": {
        "id": "x6pk978Tzv2V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dialogue_segments = extract_dialogues_nlp(formatted_text)\n",
        "\n",
        "# for segment in dialogue_segments:\n",
        "#     print(segment)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lDMkrH9H0Bbj"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(dialogue_segments)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2TwZBFpX0Ckv",
        "outputId": "932bd2a9-4af3-4fae-f348-da8a1b078bb5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "254"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_dialogue_segments(dialogue_segments):\n",
        "    cleaned_segments = []\n",
        "    for segment in dialogue_segments:\n",
        "        if not any(direction in segment.upper() for direction in ['(MOMENTS LATER)', '(CONTINUED)', 'INT.', 'EXT.']) and not any(char.isdigit() for char in segment):\n",
        "            cleaned_segments.append(segment)\n",
        "    return cleaned_segments"
      ],
      "metadata": {
        "id": "xnODWHjB0FY6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc = clean_dialogue_segments(dialogue_segments)"
      ],
      "metadata": {
        "id": "j6FgFZHm28Ee"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sc"
      ],
      "metadata": {
        "collapsed": true,
        "id": "_sKHC5oJ3IPp"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_text_in_brackets(sc):\n",
        "    cleaned_sc = []\n",
        "    for sentence in sc:\n",
        "        words = sentence.split()\n",
        "        cleaned_sentence = []\n",
        "        skip = False\n",
        "        for word in words:\n",
        "            if '(' in word:\n",
        "                skip = True\n",
        "            if not skip:\n",
        "                cleaned_sentence.append(word)\n",
        "            if ')' in word:\n",
        "                skip = False\n",
        "        cleaned_sc.append(' '.join(cleaned_sentence))\n",
        "    return cleaned_sc"
      ],
      "metadata": {
        "id": "FbHe-NaI71cU"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cleaned_sc = remove_text_in_brackets(sc)\n",
        "# for sentence in cleaned_sc:\n",
        "#     print(sentence)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jYnbXprH75rQ"
      },
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(cleaned_sc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQp225y63JIE",
        "outputId": "b97094c9-3b26-42d2-d531-7ba1149dbba1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "146"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cleaned_sc"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RduSZhji8YSF"
      },
      "execution_count": 193,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "CmTRaLLV3Rbw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(cleaned_sc)\n",
        "total_words = len(tokenizer.word_index) + 1  # Adding 1 for padding"
      ],
      "metadata": {
        "id": "zYvXjR3T3nxN"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = []\n",
        "for line in cleaned_sc:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        input_sequences.append(n_gram_sequence)"
      ],
      "metadata": {
        "id": "f4JRHy7q3x1G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# input_sequences"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SSR6Ovt02x9D"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "print(\"Max Sequence Length after padding:\", max_sequence_len)\n",
        "print(\"Shape of padded sequences:\", input_sequences.shape)"
      ],
      "metadata": {
        "id": "nbI2BjS34INq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d217a4a-ff08-4879-d863-4e67478135cd"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Sequence Length after padding: 170\n",
            "Shape of padded sequences: (5178, 170)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_sequence_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKn9ptjvAZ2a",
        "outputId": "b82948f5-8f3f-4d8e-cfb0-2e2c0f3ba18a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "170"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_sequences = np.array(input_sequences)\n",
        "\n",
        "print(input_sequences.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HqL5_s745cTN",
        "outputId": "90ef537e-3baf-410c-84a9-d89e64b08677"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5178, 170)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "LdzOos5Y46yQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = input_sequences[:,:-1], input_sequences[:,-1]"
      ],
      "metadata": {
        "id": "M3ic8qS-AChD"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_words = len(tokenizer.word_index) + 1\n",
        "y = keras.utils.to_categorical(y, num_classes=total_words)"
      ],
      "metadata": {
        "id": "nJn0Uk6J_7rb"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tz6eWWXp4MNN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape, y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxk1cv-G4QtC",
        "outputId": "b0e258e6-0c7f-4d82-e254-9963a7543dab"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5178, 169) (5178, 2026)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,)"
      ],
      "metadata": {
        "id": "hyBOAJNXBN1F"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Embedding(total_words, 100, input_length=max_sequence_len-1),\n",
        "#     tf.keras.layers.LSTM(150),\n",
        "#     tf.keras.layers.Dense(total_words, activation='softmax')\n",
        "# ])"
      ],
      "metadata": {
        "id": "0LoDiYSR4SvK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense,LSTM,Embedding,Dropout"
      ],
      "metadata": {
        "id": "zrjjng1Or4pK"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
        "model.add(LSTM(150, return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))"
      ],
      "metadata": {
        "id": "ZyZG3spO6t1l"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QqWiC-TCtBR9"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y9eJpXJUtHEt",
        "outputId": "1eff16ac-18f5-4031-c497-d1851ca00eee"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 169, 100)          202600    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 169, 150)          150600    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 169, 150)          0         \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 100)               100400    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2026)              204626    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 658226 (2.51 MB)\n",
            "Trainable params: 658226 (2.51 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', patience=30,restore_best_weights=True)"
      ],
      "metadata": {
        "id": "gHQUDdw84kFw"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=100, verbose=1, validation_data=(x_test,y_test), callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "REzBHgtY4nY4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c705ffad-4191-4645-f46a-2efddf9302ff"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 4.0587 - accuracy: 0.1439 - val_loss: 10.4400 - val_accuracy: 0.0434\n",
            "Epoch 2/100\n",
            "130/130 [==============================] - 3s 19ms/step - loss: 3.7307 - accuracy: 0.1787 - val_loss: 10.9120 - val_accuracy: 0.0405\n",
            "Epoch 3/100\n",
            "130/130 [==============================] - 2s 19ms/step - loss: 3.4681 - accuracy: 0.2277 - val_loss: 11.2148 - val_accuracy: 0.0386\n",
            "Epoch 4/100\n",
            "130/130 [==============================] - 2s 19ms/step - loss: 3.2394 - accuracy: 0.2709 - val_loss: 11.4993 - val_accuracy: 0.0405\n",
            "Epoch 5/100\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 3.0460 - accuracy: 0.3175 - val_loss: 11.7883 - val_accuracy: 0.0405\n",
            "Epoch 6/100\n",
            "130/130 [==============================] - 2s 17ms/step - loss: 2.8824 - accuracy: 0.3423 - val_loss: 11.9283 - val_accuracy: 0.0367\n",
            "Epoch 7/100\n",
            "130/130 [==============================] - 2s 19ms/step - loss: 2.7178 - accuracy: 0.3870 - val_loss: 12.1744 - val_accuracy: 0.0405\n",
            "Epoch 8/100\n",
            "130/130 [==============================] - 2s 18ms/step - loss: 2.5660 - accuracy: 0.4223 - val_loss: 12.2735 - val_accuracy: 0.0386\n",
            "Epoch 9/100\n",
            "130/130 [==============================] - 2s 18ms/step - loss: 2.4518 - accuracy: 0.4488 - val_loss: 12.4740 - val_accuracy: 0.0386\n",
            "Epoch 10/100\n",
            "130/130 [==============================] - 3s 25ms/step - loss: 2.3277 - accuracy: 0.4718 - val_loss: 12.7303 - val_accuracy: 0.0376\n",
            "Epoch 11/100\n",
            "130/130 [==============================] - 2s 19ms/step - loss: 2.1918 - accuracy: 0.5058 - val_loss: 12.8385 - val_accuracy: 0.0434\n",
            "Epoch 12/100\n",
            "130/130 [==============================] - 2s 17ms/step - loss: 2.0745 - accuracy: 0.5273 - val_loss: 12.9593 - val_accuracy: 0.0338\n",
            "Epoch 13/100\n",
            "130/130 [==============================] - 2s 18ms/step - loss: 1.9559 - accuracy: 0.5681 - val_loss: 13.2316 - val_accuracy: 0.0396\n",
            "Epoch 14/100\n",
            "130/130 [==============================] - 2s 18ms/step - loss: 1.8528 - accuracy: 0.5874 - val_loss: 13.3266 - val_accuracy: 0.0338\n",
            "Epoch 15/100\n",
            "130/130 [==============================] - 3s 26ms/step - loss: 1.7565 - accuracy: 0.6132 - val_loss: 13.3625 - val_accuracy: 0.0347\n",
            "Epoch 16/100\n",
            "130/130 [==============================] - 2s 19ms/step - loss: 1.6508 - accuracy: 0.6408 - val_loss: 13.4295 - val_accuracy: 0.0347\n",
            "Epoch 17/100\n",
            "130/130 [==============================] - 2s 18ms/step - loss: 1.5581 - accuracy: 0.6685 - val_loss: 13.6177 - val_accuracy: 0.0347\n",
            "Epoch 18/100\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 1.4808 - accuracy: 0.6849 - val_loss: 13.7650 - val_accuracy: 0.0376\n",
            "Epoch 19/100\n",
            "130/130 [==============================] - 2s 19ms/step - loss: 1.3936 - accuracy: 0.7122 - val_loss: 13.8632 - val_accuracy: 0.0319\n",
            "Epoch 20/100\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 1.3179 - accuracy: 0.7301 - val_loss: 13.8718 - val_accuracy: 0.0299\n",
            "Epoch 21/100\n",
            "130/130 [==============================] - 2s 18ms/step - loss: 1.2287 - accuracy: 0.7545 - val_loss: 14.0403 - val_accuracy: 0.0338\n",
            "Epoch 22/100\n",
            "130/130 [==============================] - 2s 18ms/step - loss: 1.1633 - accuracy: 0.7733 - val_loss: 14.0560 - val_accuracy: 0.0309\n",
            "Epoch 23/100\n",
            "130/130 [==============================] - 2s 18ms/step - loss: 1.1019 - accuracy: 0.7834 - val_loss: 14.0999 - val_accuracy: 0.0386\n",
            "Epoch 24/100\n",
            "130/130 [==============================] - 2s 19ms/step - loss: 1.0306 - accuracy: 0.8110 - val_loss: 14.2604 - val_accuracy: 0.0280\n",
            "Epoch 25/100\n",
            "130/130 [==============================] - 3s 24ms/step - loss: 0.9691 - accuracy: 0.8225 - val_loss: 14.2879 - val_accuracy: 0.0309\n",
            "Epoch 26/100\n",
            "130/130 [==============================] - 2s 17ms/step - loss: 0.9151 - accuracy: 0.8286 - val_loss: 14.3490 - val_accuracy: 0.0357\n",
            "Epoch 27/100\n",
            "130/130 [==============================] - 2s 17ms/step - loss: 0.8555 - accuracy: 0.8477 - val_loss: 14.4127 - val_accuracy: 0.0338\n",
            "Epoch 28/100\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.8050 - accuracy: 0.8609 - val_loss: 14.4636 - val_accuracy: 0.0251\n",
            "Epoch 29/100\n",
            "130/130 [==============================] - 4s 28ms/step - loss: 0.7610 - accuracy: 0.8650 - val_loss: 14.5760 - val_accuracy: 0.0299\n",
            "Epoch 30/100\n",
            "130/130 [==============================] - 3s 20ms/step - loss: 0.7177 - accuracy: 0.8822 - val_loss: 14.6320 - val_accuracy: 0.0290\n",
            "Epoch 31/100\n",
            "130/130 [==============================] - 2s 17ms/step - loss: 0.6685 - accuracy: 0.8940 - val_loss: 14.6501 - val_accuracy: 0.0309\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_with_temperature(preds, temperature=1.0):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "def predict_words(model, tokenizer, input_text, max_sequence_len, n=10, temperature=1.0):\n",
        "    for _ in range(n):\n",
        "        input_sequence = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        input_sequence = np.pad(input_sequence, (max_sequence_len-len(input_sequence)-1, 0), 'constant')\n",
        "        input_sequence = np.array([input_sequence])\n",
        "        predicted_probabilities = model.predict(input_sequence, verbose=0)[0]\n",
        "        predicted_index = sample_with_temperature(predicted_probabilities, temperature)\n",
        "\n",
        "        # Convert the predicted index to a word\n",
        "        predicted_word = None\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_index:\n",
        "                predicted_word = word\n",
        "                break\n",
        "\n",
        "        if predicted_word is None:\n",
        "            break\n",
        "        input_text += ' ' + predicted_word\n",
        "\n",
        "    return input_text"
      ],
      "metadata": {
        "id": "eICaFiGj6J2R"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Harry potter\"\n",
        "output = predict_words(model, tokenizer, input_text, max_sequence_len, n=10, temperature=0.77)\n",
        "print(f\"Output : {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-b7N5xaUMTL",
        "outputId": "33dacb20-c03b-4fa2-ace6-b4f2a540398b"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output : Harry potter the trees sight at the window they're and harry edges\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Professor. Just so you know, I don't think the map\"\n",
        "output = predict_words(model, tokenizer, input_text, max_sequence_len, n=10, temperature=0.65)\n",
        "print(f\"Output : {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiwBqIAaUXYG",
        "outputId": "2e36cbd2-a72c-426b-daae-3373fe04eff5"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output : Professor. Just so you know, I don't think the map have over the shallows of his squinting the shape thatappears\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"Sirius finds peter pettigrew is alive and among us\"\n",
        "output = predict_words(model, tokenizer, input_text, max_sequence_len, n=10, temperature=0.54)\n",
        "print(f\"Output : {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqPs_0wpaLKz",
        "outputId": "2e2dd068-83e3-468f-c438-b929e8ddf1f8"
      },
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output : Sirius finds peter pettigrew is alive and among us shock ron turns harry the invisibility would'vebetrayed ground are danger\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = \"It is not and you bloody well know\"\n",
        "output = predict_words(model, tokenizer, input_text, max_sequence_len, n=1, temperature=1)\n",
        "print(f\"Output : {output}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDNTnMD3aVjA",
        "outputId": "2eac32ff-2a06-47ab-ae5e-b3fb3cb8daea"
      },
      "execution_count": 198,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output : It is not and you bloody well know her\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dYD0-Q-ffKNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}